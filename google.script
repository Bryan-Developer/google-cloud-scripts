---
gcloud beta dataproc clusters create cluster-proyecto \
--enable-component-gateway \
--bucket bucket-staging-initial \
--region us-central1 \
--subnet default \
--zone us-central1-a \
--master-machine-type n1-standard-2 \
--master-boot-disk-size 100 \
--num-workers 3 \
--worker-machine-type n1-standard-2 \
--worker-boot-disk-size 600 \
--image-version 1.3-deb9 \
--optional-components ANACONDA,HIVE_WEBHCAT,JUPYTER,ZEPPELIN,DRUID,PRESTO,ZOOKEEPER \
--scopes 'https://www.googleapis.com/auth/cloud-platform' \
--project bryan-data-engineer
---
gcloud beta compute ssh --zone "us-central1-a" "cluster-proyecto-m" --project "bryan-data-engineer"
---
Pasos a Automatizar

gsutil cp gs://bucket-start-files/salesdb-final.zip	. \
unzip salesdb-final.zip \
USUARIO=$(whoami) \
BASE_DE_DATOS=$(ls -d */) \
cd $BASE_DE_DATOS \
hdfs dfs -mkdir -p /user/ \
DIRECTORIOS=$(ls) \
DIRECTORIOS=$(echo "${DIRECTORIOS//.csv}") \
DIRECTORIOS=( $DIRECTORIOS ) \
for i in "${DIRECTORIOS[@]}"; do hdfs dfs -mkdir -p /user/$USUARIO/$BASE_DE_DATOS/$i; done \
hdfs dfs -ls -R 

