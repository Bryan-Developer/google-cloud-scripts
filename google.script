---
gcloud beta dataproc clusters create cluster-proyecto \
--enable-component-gateway \
--bucket bucket-staging-initial \
--region us-central1 \
--subnet default \
--zone us-central1-a \
--master-machine-type n1-standard-2 \
--master-boot-disk-size 100 \
--num-workers 3 \
--worker-machine-type n1-standard-2 \
--worker-boot-disk-size 600 \
--image-version 1.3-deb9 \
--optional-components ANACONDA,HIVE_WEBHCAT,JUPYTER,ZEPPELIN,DRUID,PRESTO,ZOOKEEPER \
--scopes 'https://www.googleapis.com/auth/cloud-platform' \
--project bryan-data-engineer
---
gcloud beta compute ssh --zone "us-central1-a" "cluster-proyecto-m" --project "bryan-data-engineer"
---
Pasos a Automatizar

USUARIO=$(whoami)
gsutil cp gs://bucket-start-files/salesdb-final.zip	.
unzip salesdb-final.zip
BASE_DE_DATOS=$(ls -d */)
cd $BASE_DE_DATOS
hdfs dfs -mkdir -p /user/
DIRECTORIOS=$(ls)
DIRECTORIOS=$(echo "${DIRECTORIOS//.csv}")
DIRECTORIOS=( $DIRECTORIOS )
for i in "${DIRECTORIOS[@]}"; do hdfs dfs -mkdir -p /user/$USUARIO/$BASE_DE_DATOS/$i; done

